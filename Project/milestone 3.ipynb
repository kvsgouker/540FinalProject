{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49726149",
   "metadata": {},
   "source": [
    "Name: Kyle Salgado-Gouker <br>\n",
    "Date: October 21, 2023 <br>\n",
    "Class: DSC540 - Professor Williams <br>\n",
    "Project: Milestone 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17672451",
   "metadata": {},
   "source": [
    "### Cleaning/Formatting Website Data\n",
    "\n",
    "Perform at least 5 data transformation and/or cleansing steps to your website data. The below examples are not required - they are just potential transformations you could do. If your data doesn't work for these scenarios, complete different transformations. You can do the same transformation multiple times if needed to clean your data. The goal is a clean dataset at the end of the milestone.\n",
    "\n",
    "* Replace Headers\n",
    "* Format data into a more readable format\n",
    "* Identify outliers and bad data\n",
    "* Find duplicates\n",
    "* Fix casing or inconsistent values\n",
    "* Conduct Fuzzy Matching\n",
    "\n",
    "Make sure you clearly label each transformation step (Step #1, Step #2, etc.) in your code and describe what it is doing in 1-2 sentences. You can submit a Jupyter Notebook or a PDF of your code. If you submit a .py file you need to also include a PDF or attachment of your results.\n",
    "\n",
    "Milestone 3 is due Sunday, by Midnight of Week 8. Refer to the rubric for more grading detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67708880-b005-40bf-a748-acb19a23f3aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# file system searches etc\n",
    "import os\n",
    "from os.path import basename, exists\n",
    "import glob\n",
    "\n",
    "# regular expressions\n",
    "import re\n",
    "\n",
    "# data frames\n",
    "import pandas as pd\n",
    "# smart arrays etc (will be required)\n",
    "import numpy as np\n",
    "\n",
    "# web access and html parsing (urllib, its submodules)\n",
    "import requests\n",
    "import urllib\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "from urllib.request import urlretrieve\n",
    "# for a workaround.\n",
    "import ssl\n",
    "\n",
    "# work around read_html deprecation issue\n",
    "from io import StringIO\n",
    "\n",
    "# parser of web pages\n",
    "from bs4 import BeautifulSoup\n",
    "# more efficient parsing.\n",
    "import lxml\n",
    "\n",
    "# Fuzzy string matching\n",
    "# If necessary, here are the installation commands.\n",
    "# !pip install SciPy\n",
    "# !pip install python-Levenshtein\n",
    "# !pip install fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# for accessing sql (will be required)\n",
    "import sqlite3\n",
    "\n",
    "# fancy table printing\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed8c7a0-e27e-4a9c-adbc-c6f3fd013a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing: Make warnings fatal.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ebb5b14-64be-4348-aeee-3958d4f2da07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store final project data in its own directory.\n",
    "\n",
    "FINAL_DATA_DIRECTORY = \"data/final\"\n",
    "QT_DATA_DIRECTORY = \"data/final/QT\"\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(FINAL_DATA_DIRECTORY):\n",
    "    # If it doesn't exist, make it\n",
    "    os.makedirs(FINAL_DATA_DIRECTORY)\n",
    "    print(f\"Directory '{FINAL_DATA_DIRECTORY}' created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d53eb92-480f-43c7-9384-2387e5b02e3a",
   "metadata": {},
   "source": [
    "#### These are the URLs and Local Files for Queue-Times and Wikipedia Parks pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5cd96c4-17b6-4c97-aa97-821f8c90210c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants for accessing files and the web.\n",
    "QUEUE_TIMES_API = \"https://queue-times.com/en-US/pages/api\"\n",
    "WIKIPEDIA_PARK_RANKINGS = \"https://en.wikipedia.org/wiki/List_of_amusement_park_rankings\"\n",
    "WIKIPEDIA_PARK_RANKINGS_FILE = FINAL_DATA_DIRECTORY+\"/amusement_park_rankings.html\"\n",
    "QUEUE_TIMES_PARK_LIST_URL = \"https://queue-times.com/en-US/parks?group=country\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c41087-b182-451e-83de-09ec8cd4ade5",
   "metadata": {},
   "source": [
    "#### I set the flag below to false to skip the web scraping downloads.\n",
    "\n",
    "wip_parks.csv is the final list of parks before removing records, which is calculated through webscraping Queue Times and Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d6b5405-fbc2-4e59-8720-5a6b52da6765",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DO_QT_DOWNLOAD = False\n",
    "PARKS_WORK_IN_PROGRESS_FILE = FINAL_DATA_DIRECTORY+'/wip_parks.csv'\n",
    "PARKS_WORK_IN_PROGRESS_URL = \"https://drive.google.com/uc?id=1xoZG6VqbdMK0AgKb-eDnpvo_xenbcMiX&export=download\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2e33a34-f8fd-4b1f-b6e6-ee04c9193530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# web download function\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# download: A good citizen download function\n",
    "#     url - the url accessed\n",
    "#     destination - local file to write\n",
    "#\n",
    "# respects code 429 and waits instead of pounding.\n",
    "\n",
    "# Function to disable SSL certificate verification\n",
    "def disable_ssl_verification():\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Call the function to disable SSL verification\n",
    "# This is to workaround an SSL certificate error I am getting.\n",
    "disable_ssl_verification()\n",
    "\n",
    "def download(url, destination, secure=True):\n",
    "    try:\n",
    "        # Send a GET request with headers\n",
    "        response = requests.get(url, headers=headers, verify=secure)\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            with open(destination, 'w') as f:\n",
    "                f.write(response.text)\n",
    "            print(\"Downloaded \" + destination)\n",
    "        elif response.status_code == 429:\n",
    "            # Extract the Retry-After header value\n",
    "            # This is to avoid hammering sites.\n",
    "            retry_after = response.headers.get(\"Retry-After\")\n",
    "            if retry_after:\n",
    "                # Convert the Retry-After value to seconds\n",
    "                retry_after_seconds = int(retry_after)\n",
    "                print(\"Rate limit exceeded. Waiting for \" + str(retry_after_seconds) + \" seconds.\")\n",
    "                time.sleep(retry_after_seconds)\n",
    "                # Retry the request after waiting\n",
    "                download(url, destination)\n",
    "            else:\n",
    "                print(\"Rate limit exceeded. Retry-After header not found.\")\n",
    "        else:\n",
    "            print(\"Website returned \" + str(response.status_code))\n",
    "    except urllib.error.HTTPError:\n",
    "        print(\"Failed to download \" + url)\n",
    "    except Exception:\n",
    "        print(\"Error writing \" + destination)\n",
    "    return\n",
    "\n",
    "def downloadFile(url, filename):\n",
    "    if not exists(filename):\n",
    "        local, _ = urlretrieve(url, filename)\n",
    "        print(\"Downloaded \" + local + \"\\n\")\n",
    "        return local, _\n",
    "\n",
    "def downloadRawFile(url, filename):\n",
    "    if not os.path.exists(filename):\n",
    "        # Modify the URL to the raw content URL (replace \"github.com\" with \"raw.githubusercontent.com\")\n",
    "        raw_url = url + \"?raw=true\"\n",
    "        # Download the raw content\n",
    "        local, _ = downloadFile(raw_url, filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f503f85a-97cf-4e26-8c46-cc2c5c62aac5",
   "metadata": {},
   "source": [
    "### Download the data files for this project (so far)\n",
    "\n",
    "Download them locally. Two reasons:\n",
    "* May not be accessible this weekend.\n",
    "* Second file sometimes changes. (no surprises!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6295bc9a-a5af-4f2d-b3b6-9f08174fea6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded data/final/wip_parks.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get wikipedia ranking page.\n",
    "downloadRawFile(WIKIPEDIA_PARK_RANKINGS, WIKIPEDIA_PARK_RANKINGS_FILE)\n",
    "downloadFile(PARKS_WORK_IN_PROGRESS_URL, PARKS_WORK_IN_PROGRESS_FILE)\n",
    "\n",
    "# Workaround weird character conversion issue that started recently.\n",
    "encoding = \"utf-8\"\n",
    "# Read the HTML from the URL. Force \"utf-8\" encoding to workaround issue.\n",
    "with open(WIKIPEDIA_PARK_RANKINGS_FILE, 'r', encoding = encoding) as rankings_file:\n",
    "    # Read the contents of the file into a buffer\n",
    "    rankings_html = rankings_file.read()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff363396-f74e-47f3-b49f-03b46b8c6f7a",
   "metadata": {},
   "source": [
    "### Process Wikipedia Rankings.\n",
    "\n",
    "The most important data here are the park names and the year-by-year attendance figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c6ef006-5288-4332-9f49-ff434784f3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse wikipedia rankings using Beautiful Soup with the lxml parser\n",
    "soup = BeautifulSoup(rankings_html, 'lxml')\n",
    "\n",
    "# Get the tables\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "# Store DataFrames for each table in a list.\n",
    "dataframes = []\n",
    "\n",
    "# Skip table 0 - Corporations\n",
    "# Skip table 1 - Worldwide\n",
    "# Skip tables 6+ - Waterparks (for now)\n",
    "\n",
    "wiki_columns = ['Rank', 'Amusement park', 'Location', '2009', '2010', '2011', '2012', \n",
    "                '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
    "\n",
    "# Use these 4 tables (most popular parks in North America, Latin America, Asia, and Europe/Middle East)\n",
    "for table in tables[2:5]:\n",
    "    # Make a data frame from each table.\n",
    "    html_str = str(table)\n",
    "    # Workaround deprecation issuee.\n",
    "    html_io = StringIO(html_str)\n",
    "    # Read the HTML from the StringIO object\n",
    "    df = pd.read_html(html_io)[0]\n",
    "\n",
    "    df.columns = wiki_columns\n",
    "    # Each html page scraped is a different beast.\n",
    "    # This solves the issue with the wikipedia page parsing.\n",
    "    # Sometimes I need the text of the td item, but sometimes the name of the park is iin a title attribute\n",
    "    if 'Amusement Park' in df.columns:\n",
    "        df['Amusement Park'] = df['Amusement Park'].apply(lambda x: x['title'] if isinstance(x, dict) and 'title' in x else x)\n",
    "    # Add dataframe to a list.\n",
    "    dataframes.append(df)\n",
    "    \n",
    "# Concatenate the DataFrames into one DataFrame.\n",
    "all_wiki_amusement_parks_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Drop the 'Rank' column. Do this before finding duplicates!\n",
    "all_wiki_amusement_parks_df.drop(columns=['Rank'], inplace=True)\n",
    "\n",
    "# Remove duplicate rows based on all columns\n",
    "all_wiki_amusement_parks_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Convert all columns except 'Amusement Park' and 'Location' to numbers. Needed for stats and plotting later.\n",
    "columns_to_convert = all_wiki_amusement_parks_df.columns.difference(['Amusement park', 'Location'])\n",
    "all_wiki_amusement_parks_df[columns_to_convert] = all_wiki_amusement_parks_df[columns_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Replace NaN values with 0 in the combined DataFrame. Attendance = 0 when park is closed for pandemic, never opened, or gone for good.\n",
    "# List of columns to fill with 0\n",
    "columns_to_fillna_with_0 = ['2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
    "\n",
    "# Loop through each column and fill NaN with 0\n",
    "for column in columns_to_fillna_with_0:\n",
    "    all_wiki_amusement_parks_df[column].fillna(0, inplace=True)\n",
    "\n",
    "# Sort the data frame by Amusement park.\n",
    "all_wiki_amusement_parks_df = all_wiki_amusement_parks_df.sort_values(by='Amusement park')\n",
    "\n",
    "# Fix the column names.\n",
    "wiki_columns = ['Amusement park', 'Location', '2009', '2010', '2011', '2012', \n",
    "                '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
    "\n",
    "all_wiki_amusement_parks_df.columns = wiki_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ceed97-0594-4f6e-ac5c-f4123e3e88e5",
   "metadata": {},
   "source": [
    "### Let's see the full list of amusement parks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4538c492-b31c-45f5-a20e-f109e0483f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+-------------------------------------------+------------+------------+\n",
      "|                       Amusement park                       |                 Location                  |    2009    |    2021    |\n",
      "+------------------------------------------------------------+-------------------------------------------+------------+------------+\n",
      "|            Alton Towers at Alton Towers Resort             |           Alton, United Kingdom           | 2650000.0  | 1800000.0  |\n",
      "|                     Beto Carrero World                     |          Santa Catarina, Brazil           | 1000000.0  | 1895000.0  |\n",
      "|                  Busch Gardens Tampa Bay                   |       Tampa, Florida, United States       | 4100000.0  | 3210000.0  |\n",
      "|                    Canada's Wonderland                     |         Vaughan, Ontario, Canada          | 3160000.0  |  587000.0  |\n",
      "|                        Cedar Point                         |       Sandusky, Ohio, United States       | 2942000.0  | 3327000.0  |\n",
      "|              Chessington World of Adventures               |        Chessington, United Kingdom        | 1300000.0  | 1450000.0  |\n",
      "|                        De Efteling                         |         Kaatsheuvel, Netherlands          | 4000000.0  | 3300000.0  |\n",
      "|              Disney California Adventure Park              |    Anaheim, California, United States     | 6095000.0  | 4977000.0  |\n",
      "|    Disney's Animal Kingdom at Walt Disney World Resort     |     Bay Lake, Florida, United States      | 9590000.0  | 7194000.0  |\n",
      "|   Disney's Hollywood Studios at Walt Disney World Resort   |     Bay Lake, Florida, United States      | 9700000.0  | 8589000.0  |\n",
      "|                      Disneyland Park                       |    Anaheim, California, United States     | 15900000.0 | 8573000.0  |\n",
      "|            Disneyland Park at Disneyland Paris             |          Marne-la-Vallée, France          | 12740000.0 | 3500000.0  |\n",
      "|             Epcot at Walt Disney World Resort              |     Bay Lake, Florida, United States      | 10990000.0 | 7752000.0  |\n",
      "|             Europa-Park at Europa-Park Resort              |               Rust, Germany               | 4250000.0  | 3000000.0  |\n",
      "|                       Fantasilandia                        |              Santiago, Chile              | 1100000.0  |  615000.0  |\n",
      "|                        Futuroscope                         |            Jaunay-Clan, France            | 1700000.0  | 1100000.0  |\n",
      "|               Gardaland at Gardaland Resort                |       Castelnuovo del Garda, Italy        | 2900000.0  | 2200000.0  |\n",
      "|                         Heide Park                         |              Soltau, Germany              | 1400000.0  | 1300000.0  |\n",
      "|                        Hersheypark                         |   Hershey, Pennsylvania, United States    | 2807000.0  | 3012000.0  |\n",
      "|                        Kings Island                        |        Mason, Ohio, United States         | 3000000.0  | 3181000.0  |\n",
      "|                     Knott's Berry Farm                     |   Buena Park, California, United States   | 3333000.0  | 3681000.0  |\n",
      "|                La Feria Chapultepec Mágico                 |            Mexico City, Mexico            | 1400000.0  |    0.0     |\n",
      "|                      Legoland Billund                      |             Billund, Denmark              | 1650000.0  |  850000.0  |\n",
      "|                    Legoland Deutschland                    |             Günzburg, Germany             |    0.0     |  900000.0  |\n",
      "|                      Legoland Windsor                      |          Windsor, United Kingdom          | 1900000.0  | 1500000.0  |\n",
      "|                          Liseberg                          |            Gothenburg, Sweden             | 3150000.0  | 1447000.0  |\n",
      "|    Magic Kingdom Theme Park at Walt Disney World Resort    |     Bay Lake, Florida, United States      | 17233000.0 | 12691000.0 |\n",
      "|                        Mundo Petapa                        |         Guatemala City, Guatemala         |    0.0     |  402000.0  |\n",
      "|                        Parc Astérix                        |              Plailly, France              | 1820000.0  | 1300000.0  |\n",
      "|                   Parque Mundo Aventura                    |             Bogotá, Colombia              |    0.0     |  631000.0  |\n",
      "|                    Parque Plaza Sésamo                     |             Monterrey, Mexico             |  970000.0  |    0.0     |\n",
      "|                       Parque Warner                        |               Madrid, Spain               | 1450000.0  | 1300000.0  |\n",
      "|                       Parque Xcaret                        |              Cancun, Mexico               |    0.0     | 1104000.0  |\n",
      "|                     Parque de la Costa                     |          Buenos Aires, Argentina          |    0.0     |  395000.0  |\n",
      "|                       Phantasialand                        |              Brühl, Germany               | 1950000.0  | 1180000.0  |\n",
      "|          PortAventura Park at PortAventura World           |        Salou and Vila-seca, Spain         | 3000000.0  | 2400000.0  |\n",
      "|                         Puy du Fou                         |            Les Epesses, France            |    0.0     | 1616000.0  |\n",
      "|                      SeaWorld Orlando                      |      Orlando, Florida, United States      | 5800000.0  | 3051000.0  |\n",
      "|                     SeaWorld San Diego                     |   San Diego, California, United States    | 4200000.0  | 2800000.0  |\n",
      "|                 Six Flags Great Adventure                  |    Jackson, New Jersey, United States     | 2634000.0  | 2913000.0  |\n",
      "|                  Six Flags Great America                   |      Gurnee, Illinois, United States      |    0.0     | 2675000.0  |\n",
      "|                  Six Flags Magic Mountain                  |    Valencia, California, United States    | 2500000.0  | 3047000.0  |\n",
      "|                      Six Flags México                      |            Mexico City, Mexico            | 1950000.0  | 1125000.0  |\n",
      "|               Theme Parque Nacional del Café               |             Quindío, Colombia             |    0.0     |  482000.0  |\n",
      "|                        Thorpe Park                         |         Chertsey, United Kingdom          | 1870000.0  | 1700000.0  |\n",
      "|                       Tivoli Gardens                       |            Copenhagen, Denmark            | 3870000.0  | 2400000.0  |\n",
      "| Universal Islands of Adventure at Universal Orlando Resort |      Orlando, Florida, United States      | 4627000.0  | 9077000.0  |\n",
      "|   Universal Studios Florida at Universal Orlando Resort    |      Orlando, Florida, United States      | 5530000.0  | 8987000.0  |\n",
      "|                Universal Studios Hollywood                 | Universal City, California, United States | 4308000.0  | 5505000.0  |\n",
      "|        Walt Disney Studios Park at Disneyland Paris        |          Marne-la-Vallée, France          | 2655000.0  | 1884000.0  |\n",
      "+------------------------------------------------------------+-------------------------------------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "# print a few columns from th tables loaded.\n",
    "wiki_desired_columns = ['Amusement park', 'Location', '2009', '2021']\n",
    "print(tabulate(all_wiki_amusement_parks_df[wiki_desired_columns], headers='keys', tablefmt='pretty', showindex=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87adfbd3-55b8-456d-8c07-944b28f74cc0",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "\n",
    "* It looks like the attndance values are floating point. That's not correct.\n",
    "* The park names are not the same as the roller coaster data base, nor the queue times data base.\n",
    "* The location is more informative than the \"country\" field in queue times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4694eb69-0535-477a-8bbe-1df91b013a00",
   "metadata": {},
   "source": [
    "Last milestone I solved the issue with inconsistent park names between queue times and the roller coaster data base.\n",
    "I use the same technique here.\n",
    "\n",
    "### Introduce 2 Fields for Park Matching.\n",
    "\n",
    "* Park number: Matching Park number in Queue Times data, which will be the unique Park identifier.\n",
    "* Best match: For Fuzzy string matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f90d873-3838-480e-a35f-e2054ab3b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wiki_amusement_parks_df['Park number'] = \"\"\n",
    "all_wiki_amusement_parks_df['Best match'] = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92ba62b-a41f-480a-86d7-e3d07fc42bae",
   "metadata": {},
   "source": [
    "#### Web Scrape Queue Times for Park Numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6020321-32f1-47ff-bb12-d135f5756892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+-------------+---------------------+\n",
      "|              Amusement park               | Park number |       Country       |\n",
      "+-------------------------------------------+-------------+---------------------+\n",
      "|                Familypark                 |     322     |       Austria       |\n",
      "|                Bellewaerde                |     276     |       Belgium       |\n",
      "|               Bobbejaanland               |     311     |       Belgium       |\n",
      "|            Plopsaland De Panne            |     54      |       Belgium       |\n",
      "|              Walibi Belgium               |     14      |       Belgium       |\n",
      "|            Beto Carrero World             |     319     |       Brazil        |\n",
      "|            Canada's Wonderland            |     58      |       Canada        |\n",
      "|            La Ronde, Montreal             |     48      |       Canada        |\n",
      "|          Shanghai Disney Resort           |     30      |        China        |\n",
      "|             Djurs Sommerland              |     290     |       Denmark       |\n",
      "|             Fårup Sommerland              |     18      |       Denmark       |\n",
      "|             Legoland Billund              |     52      |       Denmark       |\n",
      "|               Alton Towers                |      1      |   United Kingdom    |\n",
      "|         Blackpool Pleasure Beach          |     273     |   United Kingdom    |\n",
      "|      Chessington World of Adventures      |      3      |   United Kingdom    |\n",
      "|             Legoland Windsor              |     27      |   United Kingdom    |\n",
      "|               Paultons Park               |     49      |   United Kingdom    |\n",
      "|                Thorpe Park                |      2      |   United Kingdom    |\n",
      "|           Disneyland Park Paris           |      4      |       France        |\n",
      "|                Futuroscope                |     291     |       France        |\n",
      "|                  Le Pal                   |     303     |       France        |\n",
      "|               PanoraMagique               |     320     |       France        |\n",
      "|               Parc Astérix                |      9      |       France        |\n",
      "|                 Vulcania                  |     304     |       France        |\n",
      "|            Walibi Rhône-Alpes             |     301     |       France        |\n",
      "|         Walt Disney Studios Paris         |     28      |       France        |\n",
      "|                Europa Park                |     51      |       Germany       |\n",
      "|                Heide Park                 |     25      |       Germany       |\n",
      "|               Holiday Park                |     302     |       Germany       |\n",
      "|           Legoland Deutschland            |     278     |       Germany       |\n",
      "|            Movie Park Germany             |     310     |       Germany       |\n",
      "|               Phantasialand               |     56      |       Germany       |\n",
      "|                 Rulantica                 |     309     |       Germany       |\n",
      "|           Disneyland Hong Kong            |     31      | Hong Kong SAR China |\n",
      "|              Cinecittà World              |     318     |        Italy        |\n",
      "|                 Gardaland                 |     12      |        Italy        |\n",
      "|              Legoland Japan               |     285     |        Japan        |\n",
      "|             Tokyo Disneyland              |     274     |        Japan        |\n",
      "|              Tokyo DisneySea              |     275     |        Japan        |\n",
      "|          Universal Studios Japan          |     284     |        Japan        |\n",
      "|             Six Flags Mexico              |     47      |       Mexico        |\n",
      "|         Avonturenpark Hellendoorn         |     323     |     Netherlands     |\n",
      "|                 Efteling                  |     160     |     Netherlands     |\n",
      "|                 Toverland                 |     305     |     Netherlands     |\n",
      "|              Walibi Holland               |     53      |     Netherlands     |\n",
      "|               Energylandia                |     317     |       Poland        |\n",
      "|              Legoland Korea               |     315     |     South Korea     |\n",
      "|               Ferrari Land                |     277     |        Spain        |\n",
      "|       Parque de Atracciones Madrid        |     321     |        Spain        |\n",
      "|           Parque Warner Madrid            |     298     |        Spain        |\n",
      "|             PortAventura Park             |     19      |        Spain        |\n",
      "|                Grona Lund                 |     166     |       Sweden        |\n",
      "|                 Liseberg                  |     11      |       Sweden        |\n",
      "|             Adventure Island              |     97      |    United States    |\n",
      "|           Adventureland Resort            |     324     |    United States    |\n",
      "|              Animal Kingdom               |      8      |    United States    |\n",
      "|             Aquatica Orlando              |     94      |    United States    |\n",
      "|           Aquatica San Antonio            |     306     |    United States    |\n",
      "|            Aquatica San Diego             |     307     |    United States    |\n",
      "|            Busch Gardens Tampa            |     24      |    United States    |\n",
      "|        Busch Gardens Williamsburg         |     23      |    United States    |\n",
      "|        California's Great America         |     57      |    United States    |\n",
      "|                 Carowinds                 |     59      |    United States    |\n",
      "|                Cedar Point                |     50      |    United States    |\n",
      "|          Discovery Cove Orlando           |     308     |    United States    |\n",
      "|        Disney California Adventure        |     17      |    United States    |\n",
      "|         Disney Hollywood Studios          |      7      |    United States    |\n",
      "|           Disney Magic Kingdom            |      6      |    United States    |\n",
      "|                Disneyland                 |     16      |    United States    |\n",
      "|                 Dollywood                 |     55      |    United States    |\n",
      "|                Dorney Park                |     69      |    United States    |\n",
      "|                   Epcot                   |      5      |    United States    |\n",
      "|               Frontier City               |     282     |    United States    |\n",
      "|                Hersheypark                |     15      |    United States    |\n",
      "| Islands Of Adventure At Universal Orlando |     64      |    United States    |\n",
      "|                 Kennywood                 |     312     |    United States    |\n",
      "|              Kings Dominion               |     62      |    United States    |\n",
      "|               Kings Island                |     60      |    United States    |\n",
      "|                 Knoebels                  |     314     |    United States    |\n",
      "|            Knott's Berry Farm             |     61      |    United States    |\n",
      "|              Lake Compounce               |     313     |    United States    |\n",
      "|            Legoland California            |     279     |    United States    |\n",
      "|             Legoland Florida              |     280     |    United States    |\n",
      "|             Legoland New York             |     299     |    United States    |\n",
      "|           Michigan's Adventure            |     70      |    United States    |\n",
      "|       Peppa Pig Theme Park Florida        |     316     |    United States    |\n",
      "|             Seaworld Orlando              |     21      |    United States    |\n",
      "|           Seaworld San Antonio            |     22      |    United States    |\n",
      "|            Seaworld San Diego             |     20      |    United States    |\n",
      "|               Sesame Place                |     29      |    United States    |\n",
      "|            Silver Dollar City             |     10      |    United States    |\n",
      "|             Six Flags America             |     42      |    United States    |\n",
      "|           Six Flags Darien Lake           |     281     |    United States    |\n",
      "|        Six Flags Discovery Kingdom        |     33      |    United States    |\n",
      "|          Six Flags Fiesta Texas           |     39      |    United States    |\n",
      "|         Six Flags Great Adventure         |     37      |    United States    |\n",
      "|          Six Flags Great America          |     38      |    United States    |\n",
      "|          Six Flags Great Escape           |     45      |    United States    |\n",
      "|   Six Flags Hurricane Harbor New Jersey   |     44      |    United States    |\n",
      "|   Six Flags Hurricane Harbor, Arlington   |     40      |    United States    |\n",
      "|    Six Flags Hurricane Harbor, Concord    |     293     |    United States    |\n",
      "|  Six Flags Hurricane Harbor, Los Angeles  |     41      |    United States    |\n",
      "|   Six Flags Hurricane Harbor, Oaxtepec    |     292     |    United States    |\n",
      "| Six Flags Hurricane Harbor, Oklahoma City |     294     |    United States    |\n",
      "|    Six Flags Hurricane Harbor, Phoenix    |     295     |    United States    |\n",
      "|   Six Flags Hurricane Harbor, Rockford    |     297     |    United States    |\n",
      "|  Six Flags Hurricane Harbor, SplashTown   |     296     |    United States    |\n",
      "|         Six Flags Magic Mountain          |     32      |    United States    |\n",
      "|           Six Flags New England           |     43      |    United States    |\n",
      "|          Six Flags Over Georgia           |     35      |    United States    |\n",
      "|           Six Flags Over Texas            |     34      |    United States    |\n",
      "|            Six Flags St. Louis            |     36      |    United States    |\n",
      "|      Six Flags White Water, Atlanta       |     46      |    United States    |\n",
      "|  Universal Studios At Universal Orlando   |     65      |    United States    |\n",
      "|        Universal Studios Hollywood        |     66      |    United States    |\n",
      "|           Universal Volcano Bay           |     67      |    United States    |\n",
      "|                Valleyfair                 |     68      |    United States    |\n",
      "|             Water Country USA             |     96      |    United States    |\n",
      "|               Worlds of Fun               |     63      |    United States    |\n",
      "+-------------------------------------------+-------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "# URL to web scrape.\n",
    "url = QUEUE_TIMES_PARK_LIST_URL\n",
    "\n",
    "# Read it.\n",
    "response = requests.get(url)\n",
    "\n",
    "# If the request was successful\n",
    "if response.status_code == 200:\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Initialize lists to store the data\n",
    "    amusement_parks = []\n",
    "    park_numbers = []\n",
    "    countries = []\n",
    "\n",
    "    # Each web page is a little different.\n",
    "    # The QT park page by country has a separate panel for each country.\n",
    "    # Inside each country panel is the park a_tag which has the data (see below)\n",
    "    #\n",
    "    # 1. Find all the <div> panels (countries)\n",
    "    div_panels = soup.find_all('div', class_='panel')\n",
    "\n",
    "    # Iterate through the countries\n",
    "    for panel in div_panels:\n",
    "        # Find the <h2> tag inside the panel\n",
    "        country_name = panel.find('h2').text.strip()\n",
    "        \n",
    "        # Find all the <a> Park tags inside the panel\n",
    "        a_tags = panel.find_all('a', class_='panel-block')\n",
    "        \n",
    "        # Iterate through the Park <a> tags\n",
    "        for a_tag in a_tags:\n",
    "            # Extract the Amusement park and link\n",
    "            amusement_park = a_tag.text.strip()\n",
    "            link = a_tag['href'] \n",
    "            amusement_park = amusement_park.split(\"\\n\")[0]\n",
    "            # Append the data to the lists\n",
    "            amusement_parks.append(amusement_park)\n",
    "            # The park number is part of the link.\n",
    "            park_numbers.append(link.split(\"/\")[-1])\n",
    "            countries.append(country_name)\n",
    "\n",
    "    # Make the dataframe from the lists collected in the scrapiing.\n",
    "    QT_park_list_df = pd.DataFrame({\n",
    "        'Amusement park': amusement_parks,\n",
    "        'Park number': park_numbers,\n",
    "        'Country': countries\n",
    "    })\n",
    "\n",
    "    # ALL DONE!\n",
    "    \n",
    "    # Display the DataFrame\n",
    "    print(tabulate(QT_park_list_df, headers='keys', tablefmt='pretty', showindex=False))\n",
    "else:\n",
    "    print(\"Failed to fetch the URL from Queue Times.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eb12e7-c2b9-4d2f-9ac5-4296174e951c",
   "metadata": {},
   "source": [
    "### Match Amusement Parks by name and move Park Number field from QT DF into Wiki DF.\n",
    "\n",
    "* Exact match\n",
    "* Near match (QT inside Wiki)\n",
    "* Near match (Wiki inside QT)\n",
    "* Fuzzy match.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708b7f5c-40ec-494b-b7f1-8472bff79d80",
   "metadata": {},
   "source": [
    "#### Note: The fuzzy matching algorithm cannot resolve a few important differences between some wikipedia/queuetime entries.\n",
    "\n",
    "They will be then be skipped in the Park Matching algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49e53199-9be5-47e1-8e94-8ecddd241fc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These parks need to be pre-set.\n",
    "\n",
    "all_wiki_amusement_parks_df.loc[all_wiki_amusement_parks_df['Amusement park'] == 'Disneyland Park', 'Park number'] = '16'\n",
    "all_wiki_amusement_parks_df.loc[all_wiki_amusement_parks_df['Amusement park'] == 'Disneyland Hong Kong', 'Park number'] = '31'\n",
    "all_wiki_amusement_parks_df.loc[all_wiki_amusement_parks_df['Amusement park'] == 'Disneyland Park at Disneyland Paris', 'Park number'] = '4'\n",
    "all_wiki_amusement_parks_df.loc[all_wiki_amusement_parks_df['Amusement park'] == 'Magic Kingdom Theme Park at Walt Disney World Resort', 'Park number'] = '6'\n",
    "all_wiki_amusement_parks_df.loc[all_wiki_amusement_parks_df['Amusement park'] == 'Walt Disney Studios Park at Disneyland Paris', 'Park number'] = '28'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29a4526-4f54-4806-8405-61e829e44d54",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style=\"color:red\">\n",
    "    <b><u>Transformation 1</u></b>: Remove parks stored in Wikipedia without Queue-Time data.\n",
    "</span>\n",
    "\n",
    "Records in wikipedia alone do not have enough info to glean impact of attraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b6fa14e6-5c7f-4823-8cfb-e97ccaa6054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # These parks need to be removed because Queue Times doesn't include them.\n",
    "indices_to_remove = [index for index, row in all_wiki_amusement_parks_df.iterrows() if row['Amusement park'] in \n",
    "                     ['Fantasilandia', 'La Feria', 'Parque Mundo Aventura', 'Parque Plaza Sésamo', 'Parque Warner', \n",
    "                      'Parque Xcaret', 'Parque de la Costa', 'Theme Parque Nacional del Café', 'Puy du Fou',\n",
    "                      'Mundo Petapa', 'Futuroscope', 'La Feria Chapultepec Mágico', 'Tivoli Gardens']]\n",
    "\n",
    "# Remove rows with the specified indices\n",
    "all_wiki_amusement_parks_df.drop(indices_to_remove, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d227f7b-0ad9-400c-b50e-aa1afdb8e49e",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "    <b><u>Transformation 2</u></b>: Introduce 'Park number', a universal key across the data sets.\n",
    "</span>\n",
    "\n",
    "### Park name matching algorithm.\n",
    "\n",
    "Sets Park number field, the QT number for the corresponding park (often with a different name.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3edae90b-2aa9-44d8-9059-ce570931937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w, row_wiki in all_wiki_amusement_parks_df.iterrows():\n",
    "    amusement_park_w = row_wiki['Amusement park']\n",
    "    \n",
    "    # Initialize variables to store the best match and its index\n",
    "    best_match_index = None\n",
    "    best_match_score = -1\n",
    "    \n",
    "    # Iterate through each row in QT_park_list_df\n",
    "    for q, row_QT in QT_park_list_df.iterrows():\n",
    "        amusement_park_Q = row_QT['Amusement park']\n",
    "        \n",
    "        # exact match first\n",
    "        if row_wiki['Park number'] == \"\" and amusement_park_w == amusement_park_Q:\n",
    "            # print(f\"Exact match for {amusement_park_w} and {amusement_park_Q}\")\n",
    "            all_wiki_amusement_parks_df.at[w, 'Park number'] = row_QT['Park number']\n",
    "            break\n",
    "            \n",
    "        # if queue time string is in wiki string\n",
    "        elif row_wiki['Park number'] == \"\" and amusement_park_w.find(amusement_park_Q) != -1:\n",
    "            # print(f\"Near match (wiki contains QT) for {amusement_park_w} and {amusement_park_Q}\")\n",
    "            all_wiki_amusement_parks_df.at[w, 'Park number'] = row_QT['Park number']\n",
    "            break\n",
    "            \n",
    "        # if wiki string is in queue time string\n",
    "        elif row_wiki['Park number'] == \"\" and amusement_park_Q.find(amusement_park_w) != -1:\n",
    "            # print(f\"Near match (QT contains wiki) for {amusement_park_w} and {amusement_park_Q}\")\n",
    "            all_wiki_amusement_parks_df.at[w, 'Park number'] = row_QT['Park number']\n",
    "            break\n",
    "            \n",
    "        # fuzzy match\n",
    "        elif row_wiki['Park number'] == \"\":\n",
    "            fuzz_score = fuzz.ratio(amusement_park_w, amusement_park_Q)\n",
    "            # print(f\"Fuzzy match for {amusement_park_w} and {amusement_park_Q}: {fuzz_score}\")\n",
    "            \n",
    "            if fuzz_score > best_match_score:\n",
    "                best_match_score = fuzz_score\n",
    "                best_match_index = q\n",
    "                \n",
    "    if all_wiki_amusement_parks_df.at[w, 'Park number'] == \"\" and best_match_index is not None:\n",
    "        all_wiki_amusement_parks_df.at[w, 'Park number'] = QT_park_list_df.at[best_match_index, 'Park number']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d96986c-6f65-4aad-bd63-07df80f0877f",
   "metadata": {},
   "source": [
    "#### Show Results of Name Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f4b1b9af-efee-4388-85f0-2589c23ff6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------------------------------------------------+\n",
      "| Park number |                       Amusement park                       |\n",
      "+-------------+------------------------------------------------------------+\n",
      "|      1      |            Alton Towers at Alton Towers Resort             |\n",
      "|     319     |                     Beto Carrero World                     |\n",
      "|     24      |                  Busch Gardens Tampa Bay                   |\n",
      "|     58      |                    Canada's Wonderland                     |\n",
      "|     50      |                        Cedar Point                         |\n",
      "|      3      |              Chessington World of Adventures               |\n",
      "|     160     |                        De Efteling                         |\n",
      "|     17      |              Disney California Adventure Park              |\n",
      "|      8      |    Disney's Animal Kingdom at Walt Disney World Resort     |\n",
      "|      7      |   Disney's Hollywood Studios at Walt Disney World Resort   |\n",
      "|     16      |                      Disneyland Park                       |\n",
      "|      4      |            Disneyland Park at Disneyland Paris             |\n",
      "|      5      |             Epcot at Walt Disney World Resort              |\n",
      "|     51      |             Europa-Park at Europa-Park Resort              |\n",
      "|     12      |               Gardaland at Gardaland Resort                |\n",
      "|     25      |                         Heide Park                         |\n",
      "|     15      |                        Hersheypark                         |\n",
      "|     60      |                        Kings Island                        |\n",
      "|     61      |                     Knott's Berry Farm                     |\n",
      "|     52      |                      Legoland Billund                      |\n",
      "|     278     |                    Legoland Deutschland                    |\n",
      "|     27      |                      Legoland Windsor                      |\n",
      "|     11      |                          Liseberg                          |\n",
      "|      6      |    Magic Kingdom Theme Park at Walt Disney World Resort    |\n",
      "|      9      |                        Parc Astérix                        |\n",
      "|     56      |                       Phantasialand                        |\n",
      "|     19      |          PortAventura Park at PortAventura World           |\n",
      "|     21      |                      SeaWorld Orlando                      |\n",
      "|     20      |                     SeaWorld San Diego                     |\n",
      "|     37      |                 Six Flags Great Adventure                  |\n",
      "|     38      |                  Six Flags Great America                   |\n",
      "|     32      |                  Six Flags Magic Mountain                  |\n",
      "|     47      |                      Six Flags México                      |\n",
      "|      2      |                        Thorpe Park                         |\n",
      "|     64      | Universal Islands of Adventure at Universal Orlando Resort |\n",
      "|     65      |   Universal Studios Florida at Universal Orlando Resort    |\n",
      "|     66      |                Universal Studios Hollywood                 |\n",
      "|     28      |        Walt Disney Studios Park at Disneyland Paris        |\n",
      "+-------------+------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "selected_columns = ['Park number', 'Amusement park']\n",
    "\n",
    "print(tabulate(all_wiki_amusement_parks_df[selected_columns], headers=selected_columns, tablefmt='pretty', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fbad2d-4b81-4144-a8e9-d1fe26e86206",
   "metadata": {},
   "source": [
    "### Now we have a uniform method of referencing parks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf12cb0-428e-4c79-a39c-0e91748a1228",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "    <b><u>Transformation 3</u></b>: Change Park (from wikipedia) column names for consistency across sets.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8a791b13-878d-4d2e-b228-b1b608a0d944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_wiki_amusement_parks_df = all_wiki_amusement_parks_df.rename(columns={'Amusement park': 'Park_Name',\n",
    "                                            'Park number': 'Park_Number'})\n",
    "\n",
    "if 'Best match' in all_wiki_amusement_parks_df.columns:\n",
    "    all_wiki_amusement_parks_df.drop(columns=['Best match'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638ad6bf-992b-4092-abca-24c4ffdbec5e",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "    <b><u>Transformation 4</u></b>: Add attendance fields from 2006-2008 and 2022+ using Queue Times\n",
    "</span>\n",
    "\n",
    "Note: This has the same source as the Wikipedia page. The Wikipedia table does not include this data.\n",
    "\n",
    "* TEA/ERA. 2008 Attraction Attendance Report. Themed Entertainment Association (TEA); 2009 https://www.teaconnect.org/images/files/TEA_23_503031_140617.pdf. Accessed 30 December, 2021.\n",
    "* TEA/ERA. 2007 Attraction Attendance Report. Themed Entertainment Association (TEA); 2008 https://www.teaconnect.org/images/files/TEA_29_601512_140617.pdf. Accessed 30 December, 2021.\n",
    "* TEA/ERA. 2006 Theme Park Attendance Report. Themed Entertainment Association (TEA); 2007 https://www.teaconnect.org/images/files/TEA_158_724007_160525.pdf. Accessed 30 December, 2021.\n",
    "* TEA/AECOM. 2022 Theme Index and Museum Index: The Global Attractions Attendance Report. Themed Entertainment Association (TEA); 2023 https://aecom.com/wp-content/uploads/documents/reports/AECOM-Theme-Index-2022.pdf. Accessed 8 July, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e40a9298-324e-479c-b04d-e0c15a75a80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns for missing years I will add from Queue Times.\n",
    "columns_to_add = ['2006', '2007', '2008', '2022']\n",
    "\n",
    "# Initialize these new columns with NaN values\n",
    "for column in columns_to_add:\n",
    "    all_wiki_amusement_parks_df = all_wiki_amusement_parks_df.assign(**{column: np.nan})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d66e87-bf6e-4ffc-bc61-eaae4a9ad604",
   "metadata": {},
   "source": [
    "#### Web Scrape of Queue Times.\n",
    "\n",
    "* Use Queue Times API to obtain Parks and Attendance. (For Transformation 4)\n",
    "* Webscrape the Queue Times Pages for Ride Entries in each park. (TODO)\n",
    "* Add missing rides to rides data base. (TODO)\n",
    "* Add missing parks to parks data base. (For Transformation 5)\n",
    "* Build transaction file of wait times using web scraping. (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be0fc46-804a-46c0-8aa0-639d93785738",
   "metadata": {},
   "source": [
    "Webscraping - First grab all the necessary web documents from Queue_Times.\n",
    "\n",
    "Use friendly download to avoid battering the server.\n",
    "\n",
    "Start with QT_park_list_df, a simple data base read from the QT parks main page.\n",
    "\n",
    "     Amusement park, Park number, Country   \n",
    "\n",
    "Files are stored in QT_DATA_DIRECTORY:\n",
    "    Optional attendance File has format: \"attendance_\"+park_number+\".html\"\n",
    "    Overall stats file has format: \"overall_stats_\"+park_number+\".html\"\n",
    "    Yearly stats files have this format: park_number+\"_\"+year+\"_stats.html\"\n",
    "\n",
    "For each park_number in list:\n",
    "* Download queue-times.com/parks/{park_number}/attendances\n",
    "* Download queue-times.com/parks/{park_number}/stats\n",
    "* stats_html = read_html\n",
    "* use soup to find all tags with format <a href=\"/parks/{park_number}/stats/* \n",
    "* these indicate the years of statistics on the site\n",
    "* for each matching year:\n",
    "* Download queue-times.com/parks/{park_number}/stats/{year}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "762ef7ab-b8ea-4c07-9b04-f80c5fd7019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_QT_DOWNLOAD:\n",
    "\n",
    "    # Get all park numbers from queue time list.\n",
    "    qt_parks = QT_park_list_df['Park number']\n",
    "\n",
    "    # For each park.\n",
    "    for qt_park in qt_parks:\n",
    "        # park *may* have attendance data. If so, grab it.\n",
    "        url_attendance = \"https://queue-times.com/parks/\" + str(qt_park) + \"/attendances\"\n",
    "        attendance_filename = QT_DATA_DIRECTORY + \"/attendance_\" + str(qt_park) + \".html\"\n",
    "\n",
    "        # Download attendance data using requests library.\n",
    "        response_attendance = requests.get(url_attendance)\n",
    "        with open(attendance_filename, 'wb') as attendance_file:\n",
    "            attendance_file.write(response_attendance.content)\n",
    "\n",
    "        # All parks should have statistics.\n",
    "        url_statistics = \"https://queue-times.com/parks/\" + str(qt_park) + \"/stats\"\n",
    "        statistics_filename = QT_DATA_DIRECTORY + \"/overall_stats_\" + str(qt_park) + \".html\"\n",
    "\n",
    "        # Download statistics data using requests library.\n",
    "        response_statistics = requests.get(url_statistics)\n",
    "        with open(statistics_filename, 'wb') as statistics_file:\n",
    "            statistics_file.write(response_statistics.content)\n",
    "\n",
    "        try:\n",
    "            # Read the HTML from the URL.\n",
    "            with open(statistics_filename, 'r') as overall_stats_file:\n",
    "                # Read the contents of the file into a buffer\n",
    "                overall_stats_html = overall_stats_file.read()\n",
    "                soup = BeautifulSoup(overall_stats_html, 'html.parser')\n",
    "\n",
    "                # Find all tags with format <a href=\"/parks/{park_number}/stats/*\n",
    "                for tag in soup.find_all('a', href=True):\n",
    "                    if f\"/parks/{qt_park}/stats/\" in tag['href']:\n",
    "                        year = tag['href'].split(\"/stats/\")[1]\n",
    "                        year_url = f'https://queue-times.com{tag[\"href\"]}'\n",
    "                        year_stats_filename = QT_DATA_DIRECTORY + f\"/{str(qt_park)}_{year}_stats.html\"\n",
    "\n",
    "                        # Download year-specific statistics data.\n",
    "                        response_year_stats = requests.get(year_url)\n",
    "                        with open(year_stats_filename, 'wb') as year_stats_file:\n",
    "                            year_stats_file.write(response_year_stats.content)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {statistics_filename}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1f4acfa4-8427-4f0c-ac9c-30f94e01b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_QT_DOWNLOAD:\n",
    "\n",
    "    # I should have downloaded the files into subfolders, but I'll move them around now.\n",
    "    # First build the directory structure.\n",
    "    # Create attendance, overall, and stats directories if they don't exist\n",
    "    for subdir in ['attendance', 'overall', 'stats']:\n",
    "        dir_path = os.path.join(QT_DATA_DIRECTORY, subdir)\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "            print(f\"Directory '{dir_path}' created.\")\n",
    "\n",
    "    # Define the year range\n",
    "    year_range = range(2014, 2024)  # From 2014-2023.\n",
    "\n",
    "    # Create subdirectories for each year within the 'stats' directory\n",
    "    for year in year_range:\n",
    "        # make subfolder name for each year.\n",
    "        dir_name = os.path.join(QT_DATA_DIRECTORY, 'stats', str(year))\n",
    "        if not os.path.exists(dir_name):\n",
    "            os.makedirs(dir_name)\n",
    "            print(f\"Directory '{dir_name}' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eeebb6ef-b25a-4831-b941-ee1ffd9679d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_QT_DOWNLOAD:\n",
    "\n",
    "    # Now move the downloaded files.\n",
    "    # ParkNumber_YearNumber_stats.html -> data/final/QT/stats/YearNumber/ParkNumber.html\n",
    "    # attendance_ParkNumber.html -> data/final/QT/attendance/ParkNumber.html\n",
    "    # overall_stats_ParkNumber.html -> data/final/QT/overall/ParkNumber.html\n",
    "\n",
    "    # Get all park numbers from the queue time list.\n",
    "    qt_parks = QT_park_list_df['Park number']\n",
    "\n",
    "    # For each park.\n",
    "    for qt_park in qt_parks:\n",
    "        # Move year stats files into each year subfolder of stats.\n",
    "        for year in year_range:\n",
    "            test_filename = os.path.join(QT_DATA_DIRECTORY, f\"{qt_park}_{year}_stats.html\")\n",
    "            if os.path.isfile(test_filename):\n",
    "                destination = os.path.join(QT_DATA_DIRECTORY, \"stats\", str(year), f\"{qt_park}.html\")\n",
    "                os.rename(test_filename, destination)\n",
    "        # Move attendance files into attendance subfolder\n",
    "        attendance_filename = os.path.join(QT_DATA_DIRECTORY, f\"attendance_{qt_park}.html\")\n",
    "        if os.path.isfile(attendance_filename):\n",
    "            destination = os.path.join(QT_DATA_DIRECTORY, \"attendance\", f\"{qt_park}.html\")\n",
    "            os.rename(attendance_filename, destination)\n",
    "        # move overall stats files into overall subfolder\n",
    "        overall_stats_filename = os.path.join(QT_DATA_DIRECTORY, f\"overall_stats_{qt_park}.html\")\n",
    "        if os.path.isfile(overall_stats_filename):\n",
    "            destination = os.path.join(QT_DATA_DIRECTORY, \"overall\", f\"{qt_park}.html\")\n",
    "            os.rename(overall_stats_filename, destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "77e2d9b0-8fce-4acc-8d00-139d472310f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the data frames before we break them (FOR DEBUGGING)\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "df_wiki_copy = all_wiki_amusement_parks_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d608e996-6098-42de-a111-96007afdb7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wiki_amusement_parks_df = df_wiki_copy.copy() # (FOR DEBUGGING. TO AVOID RELOADING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b188db00-132e-4a2a-9b89-2377f24937d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of columns to convert to integers\n",
    "string_columns = ['2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', \n",
    "                   '2017', '2018', '2019', '2020', '2021', '2022']\n",
    "\n",
    "# Iterate through numeric columns and apply conversion\n",
    "for column in string_columns:\n",
    "    all_wiki_amusement_parks_df[column] = all_wiki_amusement_parks_df[column].astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b536dca8-d1bb-4e57-a60a-7beba238f4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+-------------------------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+---------+-----------+-----------+-------------+------+------+------+------+\n",
      "|              Park_Name              |           Location            |   2009    |   2010    |   2011    |   2012    |   2013    |   2014    |   2015    |   2016    |   2017    |   2018    |  2019   |   2020    |   2021    | Park_Number | 2006 | 2007 | 2008 | 2022 |\n",
      "+-------------------------------------+-------------------------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+---------+-----------+-----------+-------------+------+------+------+------+\n",
      "| Alton Towers at Alton Towers Resort |     Alton, United Kingdom     | 2650000.0 | 2750000.0 | 2650000.0 | 2400000.0 | 2500000.0 | 2575000.0 | 1925000.0 | 1980000.0 | 2000000.0 | 2100000.0 | 2130000 | 670000.0  | 1800000.0 |      1      | nan  | nan  | nan  | nan  |\n",
      "|         Beto Carrero World          |    Santa Catarina, Brazil     | 1000000.0 | 1030000.0 | 1050000.0 | 1500000.0 | 1530000.0 | 1683000.0 | 2000000.0 | 2080000.0 | 2122000.0 | 2200000.0 | 2241000 | 1252000.0 | 1895000.0 |     319     | nan  | nan  | nan  | nan  |\n",
      "|       Busch Gardens Tampa Bay       | Tampa, Florida, United States | 4100000.0 | 4200000.0 | 4284000.0 | 4348000.0 | 4087000.0 | 4128000.0 | 4252000.0 | 4169000.0 | 3961000.0 | 4139000.0 | 4180000 | 1288000.0 | 3210000.0 |     24      | nan  | nan  | nan  | nan  |\n",
      "|         Canada's Wonderland         |   Vaughan, Ontario, Canada    | 3160000.0 | 3380000.0 | 3481000.0 | 3655000.0 | 3582000.0 | 3546000.0 | 3617000.0 | 3723000.0 | 3760000.0 | 3798000.0 | 3950000 |    0.0    | 587000.0  |     58      | nan  | nan  | nan  | nan  |\n",
      "|             Cedar Point             | Sandusky, Ohio, United States | 2942000.0 | 3051000.0 | 3143000.0 | 3221000.0 | 3382000.0 | 3247000.0 | 3507000.0 | 3604000.0 | 3604000.0 | 3676000.0 | 3610000 | 1020000.0 | 3327000.0 |     50      | nan  | nan  | nan  | nan  |\n",
      "+-------------------------------------+-------------------------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+---------+-----------+-----------+-------------+------+------+------+------+\n",
      "QT Before Rename\n",
      "+---------------------+-------------+---------+\n",
      "|   Amusement park    | Park number | Country |\n",
      "+---------------------+-------------+---------+\n",
      "|     Familypark      |     322     | Austria |\n",
      "|     Bellewaerde     |     276     | Belgium |\n",
      "|    Bobbejaanland    |     311     | Belgium |\n",
      "| Plopsaland De Panne |     54      | Belgium |\n",
      "|   Walibi Belgium    |     14      | Belgium |\n",
      "+---------------------+-------------+---------+\n",
      "QT after Rename\n",
      "+---------------------+-------------+----------+\n",
      "|      Park_Name      | Park_Number | Location |\n",
      "+---------------------+-------------+----------+\n",
      "|     Familypark      |     322     | Austria  |\n",
      "|     Bellewaerde     |     276     | Belgium  |\n",
      "|    Bobbejaanland    |     311     | Belgium  |\n",
      "| Plopsaland De Panne |     54      | Belgium  |\n",
      "|   Walibi Belgium    |     14      | Belgium  |\n",
      "+---------------------+-------------+----------+\n"
     ]
    }
   ],
   "source": [
    "selected_columns = all_wiki_amusement_parks_df.columns\n",
    "print(tabulate(all_wiki_amusement_parks_df[selected_columns].head(5), headers=selected_columns, tablefmt='pretty', showindex=False))\n",
    "\n",
    "print(\"QT Before Rename\")\n",
    "selected_columns = QT_park_list_df.columns\n",
    "print(tabulate(QT_park_list_df[selected_columns].head(5), headers=selected_columns, tablefmt='pretty', showindex=False))\n",
    "\n",
    "\n",
    "# Define a dictionary to map the old column names to the new names\n",
    "column_mapping = {\n",
    "    'Amusement park': 'Park_Name',\n",
    "    'Park number': 'Park_Number',\n",
    "    'Country': 'Location'\n",
    "}\n",
    "\n",
    "# Use the rename method to rename the columns\n",
    "QT_park_list_df = QT_park_list_df.rename(columns=column_mapping)\n",
    "\n",
    "# Now the columns should be renamed\n",
    "print(\"QT after Rename\")\n",
    "selected_columns = QT_park_list_df.columns\n",
    "print(tabulate(QT_park_list_df[selected_columns].head(5), headers=selected_columns, tablefmt='pretty', showindex=False))\n",
    "\n",
    "# Define the desired column order\n",
    "desired_order = [\"Park_Number\", \"Park_Name\", \"Location\"] + [str(year) for year in range(2006, 2023)]\n",
    "\n",
    "# Reorder the columns\n",
    "all_wiki_amusement_parks_df = all_wiki_amusement_parks_df[desired_order]\n",
    "\n",
    "all_wiki_amusement_parks_df.to_csv(FINAL_DATA_DIRECTORY+'/original_web_parks.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ea7dec-e525-43e2-8e2c-9599f62e7616",
   "metadata": {},
   "source": [
    "#### Load Attendance Data (if available) for all parks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cdea55-4a49-4f33-b2d2-c1283ad81479",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "    <b><u>Transformation 5</u></b>: Side effect of Transformation 4 - adds records that are candidates for data set.\n",
    "</span>\n",
    "\n",
    "This code loads the webscraped html tables and transfers the Queue-Timess 2006-2008 and 2022 data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "19fe1a60-1193-439b-b0b2-4c40525ba5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119  park records after processing attendance.\n"
     ]
    }
   ],
   "source": [
    "def convert_data_types(df):\n",
    "    # Convert all columns (except 'Park_Number') to string\n",
    "    columns_to_string = df.columns.difference(['Park_Number'])\n",
    "    df[columns_to_string] = df[columns_to_string].astype(str)\n",
    "    # Convert 'Park_Number' to int\n",
    "    df['Park_Number'] = df['Park_Number'].astype(int)\n",
    "    return df\n",
    "\n",
    "all_wiki_amusement_parks_df = convert_data_types(all_wiki_amusement_parks_df)\n",
    "wiki_database_columns = ['Park_Number', 'Park_Name', 'Location', '2006', '2007', '2008', '2009', '2010', \n",
    "                        '2011', '2012', '2013', '2014', '2015', \n",
    "                        '2016', '2017', '2018', '2019', '2020', '2021', '2022']\n",
    "\n",
    "if DO_QT_DOWNLOAD:\n",
    "    parks_df = pd.DataFrame(columns=wiki_database_columns)\n",
    "\n",
    "    print(len(all_wiki_amusement_parks_df), \" park records before processing attendance.\")\n",
    "\n",
    "    attendance_dir = os.path.join(QT_DATA_DIRECTORY, \"attendance\")\n",
    "\n",
    "    for filename in os.listdir(attendance_dir):\n",
    "        if filename.endswith(\".html\"):\n",
    "            # Extract park_number from the filename\n",
    "            park_number = filename.split(\".\")[0]\n",
    "\n",
    "            qt_matching_record = QT_park_list_df[QT_park_list_df['Park_Number'] == park_number].iloc[0]\n",
    "\n",
    "            print(\"Processing park \", park_number, \". Park name = \", qt_matching_record['Park_Name'])\n",
    "\n",
    "            # Check if the record exists in the DataFrame\n",
    "\n",
    "            matching_record_df = all_wiki_amusement_parks_df[all_wiki_amusement_parks_df['Park_Number'] == int(park_number)]\n",
    "\n",
    "            if matching_record_df.empty:\n",
    "                new_data = {'Park_Number': int(park_number),\n",
    "                            'Park_Name': qt_matching_record['Park_Name'],\n",
    "                            'Location': qt_matching_record['Location']}\n",
    "                # set attendance data to nan if unknown.\n",
    "                for year in range(2006, 2023):\n",
    "                    new_data[str(year)] = np.nan\n",
    "\n",
    "                print(\"Adding new record: Attendance Data for park \", park_number, \". Park name = \", qt_matching_record['Park_Name'])\n",
    "                # initialize dataframe with new record.\n",
    "                matching_record_df = pd.DataFrame([new_data])\n",
    "                matching_record_df = convert_data_types(matching_record_df)\n",
    "\n",
    "            # restrict to necessary coolumns\n",
    "            matching_record_df = matching_record_df[wiki_database_columns]\n",
    "            # get the 0th record of the frame (make it a series) - NOTE: There is only ever one.\n",
    "            # Avoid slice by working on a copy.\n",
    "            matching_record = matching_record_df.iloc[0].copy()\n",
    "\n",
    "            # Read the downloaded file,\n",
    "            with open(os.path.join(attendance_dir, filename), 'r', encoding='utf-8') as attendance_file:\n",
    "                attendance_html = attendance_file.read()\n",
    "\n",
    "            # Use soup to get the ttable.\n",
    "            soup = BeautifulSoup(attendance_html, 'html.parser')\n",
    "            attendance_table = soup.find('table', {'class': 'table is-fullwidth'})\n",
    "\n",
    "            if attendance_table:\n",
    "                # Use Pandas to read the HTML table into a DataFrame\n",
    "                html_str = str(attendance_table)\n",
    "                # Workaround deprecation issuee.\n",
    "                html_io = StringIO(html_str)\n",
    "                # Read the HTML from the StringIO object\n",
    "                # Take the first DataFrame in the list:\n",
    "                attendance_df = pd.read_html(html_io)[0]\n",
    "\n",
    "                # Convert 'Year' and 'Attendance' columns to appropriate data types\n",
    "                # The table entries have junk besides numbers in them.\n",
    "                attendance_df['Year'] = attendance_df['Year'].astype(str).str.extract(r'(\\d+)').astype(int)\n",
    "                # The Attendance has a 'footnote' - I use a regular expression to grab the number.\n",
    "                attendance_df['Attendance'] = attendance_df['Attendance'].astype(str).str.replace(',', '', regex=True).str.extract(r'(\\d+)').astype(int)\n",
    "\n",
    "                # use the park name and location from queue times as the 'correct' names\n",
    "                # I already set park name in roller coaster data base to match the QT park name.\n",
    "                matching_record['Park_Name'] = qt_matching_record['Park_Name']\n",
    "                # Do not change Location. It is more descriptive than QT's, Country alone.\n",
    "\n",
    "                # Set each year in matching_record to the Attendance in attendance_df\n",
    "                for year in range(2006, 2023):\n",
    "                    attendance_year_test_df = attendance_df[attendance_df['Year'] == year]\n",
    "                    if not attendance_year_test_df.empty:\n",
    "                        attendance_value = attendance_year_test_df['Attendance'].values[0]\n",
    "                        matching_record[str(year)] = attendance_value\n",
    "                        # print(\"Park: \", park_number, \". Name: \", qt_matching_record['Park_Name'],\n",
    "                        #       \". Year: \", year, \". Attendance: \", attendance_value)\n",
    "\n",
    "            # add new record\n",
    "            parks_df = pd.concat([parks_df, pd.DataFrame([matching_record], columns=wiki_database_columns)], ignore_index=True)\n",
    "            parks_df.to_csv(FINAL_DATA_DIRECTORY+'/wip_parks.csv', index=False)\n",
    "else:\n",
    "    parks_df = pd.read_csv(FINAL_DATA_DIRECTORY+'/wip_parks.csv')\n",
    "    \n",
    "print(len(parks_df), \" park records after processing attendance.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0605af1f-d1f2-45e8-abf5-7885265a10af",
   "metadata": {},
   "source": [
    "#### The new dataframe, park_df, has 81 new possible candidates for inclusion.\n",
    "\n",
    "\n",
    "Note: Most of these will be removed later, because of too many nan columns.\n",
    "\n",
    "#### The code below shows the current state. Only selected columns are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d3361c81-bc40-40bd-8e32-558d0a4173c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------------------+----------+----------+----------+----------+---------+----------+\n",
      "| Park_Number |          Park_Name           |   2006   |   2007   |   2008   |   2015   |  2020   |   2022   |\n",
      "+-------------+------------------------------+----------+----------+----------+----------+---------+----------+\n",
      "|     317     |         Energylandia         |    0     |    0     |    0     |    0     |    0    |    0     |\n",
      "|     23      |  Busch Gardens Williamsburg  |    0     | 3157000  | 3094000  |    0     |    0    |    0     |\n",
      "|     301     |      Walibi Rhône-Alpes      |    0     |    0     |    0     |    0     |    0    |    0     |\n",
      "|     35      |    Six Flags Over Georgia    |    0     |    0     |    0     |    0     |    0    |    0     |\n",
      "|     62      |        Kings Dominion        |    0     |    0     |    0     |    0     |    0    |    0     |\n",
      "|      9      |         Parc Astérix         | 1800000  | 1620000  | 1800000  | 1850000  | 1163000 | 2632000  |\n",
      "|     19      |      PortAventura Park       | 3500000  | 3700000  | 3300000  | 3600000  | 700000  | 3750000  |\n",
      "|     58      |     Canada's Wonderland      | 3230000  | 3250000  | 3380000  | 3617000  |    0    | 3768000  |\n",
      "|     291     |         Futuroscope          | 1350000  | 1600000  | 1600000  | 1800000  | 900000  | 1920000  |\n",
      "|     97      |       Adventure Island       |  609000  |  615000  |  603000  |  663000  | 125000  |  636000  |\n",
      "|     39      |    Six Flags Fiesta Texas    |    0     |    0     |    0     |    0     |    0    |    0     |\n",
      "|      5      |            Epcot             | 10460000 | 10930000 | 10935000 | 11798000 | 4044000 | 10000000 |\n",
      "|     15      |         Hersheypark          | 2690000  | 2940000  | 2842000  | 3276000  | 1717000 | 3193000  |\n",
      "|     321     | Parque de Atracciones Madrid |    0     |    0     |    0     |    0     |    0    |    0     |\n",
      "|     42      |      Six Flags America       |    0     |    0     |    0     |    0     |    0    |    0     |\n",
      "|     54      |     Plopsaland De Panne      |    0     |    0     |    0     |    0     |    0    |    0     |\n",
      "|     273     |   Blackpool Pleasure Beach   |    0     |    0     |    0     |    0     |    0    |    0     |\n",
      "|     55      |          Dollywood           |    0     |    0     |    0     |    0     |    0    |    0     |\n",
      "|     43      |    Six Flags New England     |    0     |    0     |    0     |    0     |    0    |    0     |\n",
      "|     320     |        PanoraMagique         |    0     |    0     |    0     |    0     |    0    |    0     |\n",
      "|     14      |        Walibi Belgium        |    0     |    0     |    0     |    0     |    0    |    0     |\n",
      "|      4      |    Disneyland Park Paris     | 10600000 | 12000000 | 12688000 | 9790000  | 2620000 | 9930000  |\n",
      "|     160     |           Efteling           | 3200000  | 3200000  | 3200000  | 4680000  | 2900000 | 5430000  |\n",
      "|     38      |   Six Flags Great America    |    0     |    0     |    0     | 2793000  |    0    | 2535000  |\n",
      "|     96      |      Water Country USA       |  670000  |  773000  |  758000  |  726000  |    0    |  707000  |\n",
      "+-------------+------------------------------+----------+----------+----------+----------+---------+----------+\n"
     ]
    }
   ],
   "source": [
    "selected_columns=['Park_Number', 'Park_Name', '2006', '2007', '2008', '2015', '2020', '2022']\n",
    "print(tabulate(parks_df[selected_columns].head(25), headers=selected_columns, tablefmt='pretty', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9d9560-12f8-4b50-8231-06a519b4b43d",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "    <b><u>Transformation 6</u></b>: Change Park (from wikipedia) data types for attendance numbers etc.\n",
    "</span>\n",
    "\n",
    "* Park_Number should be an int64\n",
    "* Park_Name should be a string.\n",
    "* Location should be a string.\n",
    "* 2006-2022 should be int64 (transform from float as necessary)\n",
    "\n",
    "Coerce and FillNA as needed. Change NAN to zeroes.\n",
    "\n",
    "First show the current state:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd66184-695d-4702-8cac-d79caf3a542a",
   "metadata": {},
   "source": [
    "#### Function to Show Column Name and Data Type for a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "48a973eb-39c7-4e40-a27d-52239996b3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metadata(df):\n",
    "    metadata_df = pd.DataFrame({\n",
    "        \"Data Type\": df.dtypes\n",
    "    })\n",
    "    print(tabulate(metadata_df, headers=['Field Name', 'Data Type'], tablefmt='pretty'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35192b71-67ad-4bc9-8c3f-6354bf160ef7",
   "metadata": {},
   "source": [
    "#### Some of the Fields are Incorrectly Typed in Both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d2e9e4f7-7fb2-4056-90bc-541ca5e7fd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fields of Park Data Frame\n",
      "+-------------+-----------+\n",
      "| Field Name  | Data Type |\n",
      "+-------------+-----------+\n",
      "| Park_Number |   int64   |\n",
      "|  Park_Name  |  object   |\n",
      "|  Location   |  object   |\n",
      "|    2006     |   int64   |\n",
      "|    2007     |   int64   |\n",
      "|    2008     |   int64   |\n",
      "|    2009     |   int64   |\n",
      "|    2010     |   int64   |\n",
      "|    2011     |   int64   |\n",
      "|    2012     |   int64   |\n",
      "|    2013     |   int64   |\n",
      "|    2014     |   int64   |\n",
      "|    2015     |   int64   |\n",
      "|    2016     |   int64   |\n",
      "|    2017     |   int64   |\n",
      "|    2018     |   int64   |\n",
      "|    2019     |   int64   |\n",
      "|    2020     |   int64   |\n",
      "|    2021     |   int64   |\n",
      "|    2022     |   int64   |\n",
      "+-------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFields of Park Data Frame\")\n",
    "show_metadata(parks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "73c2d387-f080-4889-85fc-3e325f5c7143",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the data type conversions for the specified columns\n",
    "data_type_conversions = {\n",
    "    'Park_Name': 'string',\n",
    "    'Location': 'string',\n",
    "    'Park_Number': 'int64'\n",
    "}\n",
    "\n",
    "# Define the list of columns to convert to integers\n",
    "attendance_columns = ['2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022']\n",
    "\n",
    "# Iterate through numeric columns and apply conversion\n",
    "for column in attendance_columns:\n",
    "    parks_df[column] = pd.to_numeric(parks_df[column], errors='coerce').fillna(0).astype('int64')\n",
    "\n",
    "# Apply data type conversions to the DataFrame\n",
    "parks_df = parks_df.astype(data_type_conversions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd511ba1-220e-4c56-87c3-ccc5c4aca912",
   "metadata": {},
   "source": [
    "#### Show New Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "38ededb2-3fae-4d5b-92ed-35bfcfadb32c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fields of Park Data Frame\n",
      "+-------------+-----------+\n",
      "| Field Name  | Data Type |\n",
      "+-------------+-----------+\n",
      "| Park_Number |   int64   |\n",
      "|  Park_Name  |  string   |\n",
      "|  Location   |  string   |\n",
      "|    2006     |   int64   |\n",
      "|    2007     |   int64   |\n",
      "|    2008     |   int64   |\n",
      "|    2009     |   int64   |\n",
      "|    2010     |   int64   |\n",
      "|    2011     |   int64   |\n",
      "|    2012     |   int64   |\n",
      "|    2013     |   int64   |\n",
      "|    2014     |   int64   |\n",
      "|    2015     |   int64   |\n",
      "|    2016     |   int64   |\n",
      "|    2017     |   int64   |\n",
      "|    2018     |   int64   |\n",
      "|    2019     |   int64   |\n",
      "|    2020     |   int64   |\n",
      "|    2021     |   int64   |\n",
      "|    2022     |   int64   |\n",
      "+-------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFields of Park Data Frame\")\n",
    "show_metadata(parks_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96210bd2-1543-4e90-a989-c433b7407814",
   "metadata": {
    "tags": []
   },
   "source": [
    "That's good.\n",
    "\n",
    "##### Note: TODO.\n",
    "\n",
    "The Ride Data Frame will need further type changes:\n",
    "\n",
    "* Opening_Date will be a TimeStamp\n",
    "* Height, Length, Speed, Drop, Max_Vertical_Angle, G-force, and Height_Restriction will be float64\n",
    "* Cost will be a currency\n",
    "* Inversions and Capacity will be int64\n",
    "* Duration will be a time.\n",
    "\n",
    "Unfortunately, these will require more parsing.\n",
    "Fortunately, they are not <i>yet</i> required for this project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c18077-4156-4d35-89c5-90bcaff7b0dc",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "    <b><u>Transformation 7</u></b>: Drop 2020 and 2021 columns. COVID impact.<p>    \n",
    "</span>\n",
    "\n",
    "Apply this only to a copy of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fd4eb6d7-f173-4217-8db6-c6237ee817c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_attendance_subset_df = parks_df.copy()\n",
    "\n",
    "columns_to_drop = ['2020', '2021']\n",
    "\n",
    "parks_attendance_subset_df = parks_attendance_subset_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f49234d-0301-44a3-ac20-11f4cc095af9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style=\"color:red\">\n",
    "    <b><u>Transformation 8</u></b>: Drop rows with only zero or nan attendance data.<p>    \n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c08b5b6c-96b5-4c56-be5b-678cfc2a4ddd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54  park records after final drops.\n"
     ]
    }
   ],
   "source": [
    "# Columns to check for NaN or zero values\n",
    "# I have already removed 2020 and 2021\n",
    "attendance_columns = [str(year) for year in range(2006, 2020)] + ['2022']\n",
    "\n",
    "# Define boolean mask for NaN or zero values in the specified columns.\n",
    "mask = (parks_df[attendance_columns] == 0) | parks_df[attendance_columns].isna()\n",
    "# ALL attendance columns must be NaN or zero to drop the record.\n",
    "mask = mask.all(axis=1)\n",
    "\n",
    "# Drop rows that satisfy the condition\n",
    "filtered_parks_df = parks_df[~mask]\n",
    "\n",
    "print(len(filtered_parks_df), \" park records after final drops.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ebf027-6dd4-459f-9016-75218b8c557d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Store this result to csv.\n",
    "\n",
    "#### Store Parks Data Frame to CSV file (backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8777334c-bce9-4d56-9156-b14a14c9f3e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_parks_df.to_csv(FINAL_DATA_DIRECTORY+'/final_web_parks.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37ac664-fbaf-4dd6-a07a-776fd63522bb",
   "metadata": {},
   "source": [
    "#### ROW Tally Explanation.\n",
    "\n",
    "So, the Wikipedia set had 38 records. That was augmented via QueueTime to 119.\n",
    "The only records with attendance data are these 54.\n",
    "\n",
    "This is the data that will be stored in SQl table, parks_subset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ee75ea-b77a-46db-84f3-636afffc02ee",
   "metadata": {},
   "source": [
    "#### TODO: Create Transaction Files from QUEUE-TIME.\n",
    "\n",
    "* Shows how queue-lines change\n",
    "* Shows effects of seasons and days of week.\n",
    "\n",
    "##### These will also be SQL tables.\n",
    "\n",
    "Here is the creation of SQL tables for the database and filtered database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127ce009-5def-4a92-a2a7-3f3a04f8881b",
   "metadata": {},
   "source": [
    "#### Set up an SQL Data Base to Facilitate Queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d497bdc6-3c6f-4458-8bc5-e433f0cd1985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to SQLite database\n",
    "conn = sqlite3.connect(FINAL_DATA_DIRECTORY+'/park_info.db')\n",
    "\n",
    "# First get rid of previous data tables. We regen every time for now.\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Drop the table\n",
    "cursor.execute('DROP TABLE IF EXISTS parks')\n",
    "cursor.execute('DROP TABLE IF EXISTS parks_subset')\n",
    "\n",
    "# Write dataframes to SQLite\n",
    "parks_df.to_sql(name='parks', con=conn, if_exists='replace', index = False, index_label=['Park_Name', 'Park_Number'])\n",
    "filtered_parks_df.to_sql(name='parks_subset', con=conn, if_exists='replace', index = False, index_label=['Park_Name', 'Park_Number'])\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbbacd9-4eea-439e-99b2-c1d7da046e83",
   "metadata": {},
   "source": [
    "#### Helper Functions for Implementing SQL Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6fb196aa-08d6-40af-acd1-c9f7051ef501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printFormattedTestStat(value, dec=2):\n",
    "    format_string = \"{:.{dec}f}\"\n",
    "    return format_string.format(value, dec=dec)\n",
    "\n",
    "def printCurrencyFormattedTestStat(value, dec=2):\n",
    "    format_string = \"{:,.{dec}f}\"\n",
    "    return format_string.format(value, dec=dec)\n",
    "\n",
    "\n",
    "calculated_columns = []\n",
    "currency_columns = []\n",
    "\n",
    "def testSqlAccess(cursor, request, title, column_names=None, hdr = None):\n",
    "    cursor.execute(request)\n",
    "    test_data = cursor.fetchall()\n",
    "    if column_names is None:\n",
    "        column_names = [description[0] for description in cursor.description]\n",
    "    test_df = pd.DataFrame(test_data, columns=[description[0] for description in cursor.description])\n",
    "    selected_columns = [col for col in column_names if col in test_df.columns]\n",
    "    if hdr != None:\n",
    "        headers = hdr\n",
    "    else:\n",
    "        headers = selected_columns\n",
    "    formatted_df = test_df[selected_columns].copy()\n",
    "    for col in selected_columns:\n",
    "        if col in calculated_columns:\n",
    "            formatted_df[col] = formatted_df[col].map(lambda x: printFormattedTestStat(x))\n",
    "        if col in currency_columns:\n",
    "            formatted_df[col] = formatted_df[col].map(lambda x: printCurrencyFormattedTestStat(x))\n",
    "\n",
    "    print(\"\\n\" + title + \"\\n\")\n",
    "    print(tabulate(formatted_df, headers=headers, tablefmt='psql', showindex=False))\n",
    "    return formatted_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ee6bb758-ded8-4851-8b9b-162ef0dbd7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Florida Parks\n",
      "\n",
      "+-------------------------------------------+---------------+----------------------------------+\n",
      "| Park_Name                                 |   Park_Number | Location                         |\n",
      "|-------------------------------------------+---------------+----------------------------------|\n",
      "| Epcot                                     |             5 | Bay Lake, Florida, United States |\n",
      "| Animal Kingdom                            |             8 | Bay Lake, Florida, United States |\n",
      "| Islands Of Adventure At Universal Orlando |            64 | Orlando, Florida, United States  |\n",
      "| Universal Studios At Universal Orlando    |            65 | Orlando, Florida, United States  |\n",
      "| Busch Gardens Tampa                       |            24 | Tampa, Florida, United States    |\n",
      "| Seaworld Orlando                          |            21 | Orlando, Florida, United States  |\n",
      "| Disney Hollywood Studios                  |             7 | Bay Lake, Florida, United States |\n",
      "| Disney Magic Kingdom                      |             6 | Bay Lake, Florida, United States |\n",
      "+-------------------------------------------+---------------+----------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Park_Name</th>\n",
       "      <th>Park_Number</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Epcot</td>\n",
       "      <td>5</td>\n",
       "      <td>Bay Lake, Florida, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal Kingdom</td>\n",
       "      <td>8</td>\n",
       "      <td>Bay Lake, Florida, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Islands Of Adventure At Universal Orlando</td>\n",
       "      <td>64</td>\n",
       "      <td>Orlando, Florida, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Universal Studios At Universal Orlando</td>\n",
       "      <td>65</td>\n",
       "      <td>Orlando, Florida, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Busch Gardens Tampa</td>\n",
       "      <td>24</td>\n",
       "      <td>Tampa, Florida, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Seaworld Orlando</td>\n",
       "      <td>21</td>\n",
       "      <td>Orlando, Florida, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Disney Hollywood Studios</td>\n",
       "      <td>7</td>\n",
       "      <td>Bay Lake, Florida, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Disney Magic Kingdom</td>\n",
       "      <td>6</td>\n",
       "      <td>Bay Lake, Florida, United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Park_Name  Park_Number  \\\n",
       "0                                      Epcot            5   \n",
       "1                             Animal Kingdom            8   \n",
       "2  Islands Of Adventure At Universal Orlando           64   \n",
       "3     Universal Studios At Universal Orlando           65   \n",
       "4                        Busch Gardens Tampa           24   \n",
       "5                           Seaworld Orlando           21   \n",
       "6                   Disney Hollywood Studios            7   \n",
       "7                       Disney Magic Kingdom            6   \n",
       "\n",
       "                           Location  \n",
       "0  Bay Lake, Florida, United States  \n",
       "1  Bay Lake, Florida, United States  \n",
       "2   Orlando, Florida, United States  \n",
       "3   Orlando, Florida, United States  \n",
       "4     Tampa, Florida, United States  \n",
       "5   Orlando, Florida, United States  \n",
       "6  Bay Lake, Florida, United States  \n",
       "7  Bay Lake, Florida, United States  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with SQL query.\n",
    "\n",
    "# query all rides with Kings Island \n",
    "\n",
    "\n",
    "park_columns_1 = [\"Park_Name\", \"Park_Number\", \"Location\"]\n",
    "\n",
    "testSqlAccess(cursor, \"SELECT * FROM parks WHERE Location LIKE '%Florida%'\", \"Florida Parks\", column_names = park_columns_1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
